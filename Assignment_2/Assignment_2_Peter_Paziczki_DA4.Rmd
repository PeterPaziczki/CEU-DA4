---
title: "Homework assignment 2"
author: "Peter Paziczki"
date: "2018 February 18"
output:
  html_document: default
  pdf_document: default
subtitle: 'Data Analysis 4: Prediction Analytics with Introduction to Machine Learning
  2017/2018 Winter'
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(warning = FALSE, echo = FALSE)
options(scipen=999) # disabling scientific notation
```

```{r include=FALSE}
# loading necessary 
library(data.table)
library(ggplot2)
library(tidyr)
library(DescTools) # for BrierScore function
library(pROC) # for roc function
library(dplyr)
library(randomForest)
#library(lattice)
#library(caret)
#library(glmnet)
```

### 1. Predicting firm default

We have been provided the bisnode_all.csv dataset containing more than 150.000 observations, covering financial data from 2011 to 2016, management related information and further information about employment and industrial classification. Our task is to define firm default and build models that can predict it.

```{r include=FALSE}
## Loading the bisnode data
bisnode_all <- fread("bisnode_all.csv")
```

```{r include=FALSE}
## Creating a table with unique company IDs and sales values from all years
data_sales <- bisnode_all[, c("comp_id", "sales", "year")]
data_sales <- spread(data_sales, key = year, value = sales)
names(data_sales) <- c("comp_id", "sales_2011", "sales_2012", "sales_2013", "sales_2014", "sales_2015", "sales_2016")

## Dropping the year 2016, because when the data was gathered, not all the the companies have submitted their financial records for 2016.
data_sales[,"sales_2016" := NULL]

## Keeping companies that have no NA records in years 2011 to 2013
data <- data_sales[complete.cases(data_sales[,c("sales_2011", "sales_2012", "sales_2013")]),]
```

```{r include=FALSE}
## computing the percentage changes in sales from year to year
data[, sales_change_11_12 := sales_2012/sales_2011]
data[, sales_change_12_13 := sales_2013/sales_2012]
data[, sales_change_13_14 := sales_2014/sales_2013]
data[, sales_change_14_15 := sales_2015/sales_2014]
```

```{r include=FALSE}
## Creating binary variables

#data[, sales_2011_is_NA := factor(ifelse(is.na(data[,sales_2011]), 1, 0))]
#data[, sales_2012_is_NA := factor(ifelse(is.na(data[,sales_2012]), 1, 0))]
#data[, sales_2013_is_NA := factor(ifelse(is.na(data[,sales_2013]), 1, 0))]
data[, sales_2014_is_NA := factor(ifelse(is.na(data[,sales_2014]), 1, 0))]
data[, sales_2015_is_NA := factor(ifelse(is.na(data[,sales_2015]), 1, 0))]
#data[, sales_2016_is_NA := factor(ifelse(is.na(data[,sales_2016]), 1, 0))]
```

#### 1.1 Defining firm default

I am going to consider a firm defaulted if there are no records about its sales results in 2014 and 2015. Having no records means that it is either zero and / or missing. I could see many examples of missing sales records, but two missing records in row is enough for me to say that the company has defaulted.

It also means that I cannot work with companies founded later than 2013. Companies that had zero as record of sales in all years from 2011 to 2013 have also been dropped, those are considered as inactive, irrelevant for our study.

#### 1.2 Data preparation

I have dropped the year 2016, because when the data was gathered, not all the the companies have submitted their financial records for 2016.

```{r include=FALSE}
## Defining firm default

#data[,defaulted := factor(ifelse(sales_2014_is_NA == 1 & sales_2015_is_NA == 1, 1, 0))]
data[,defaulted := ifelse(sales_2014_is_NA == 1 & sales_2015_is_NA == 1 | 
                                        sales_2014 == 0 & sales_2015 == 0 | 
                                        sales_2014 == 0 & sales_2015_is_NA == 1 |
                                        sales_2014_is_NA == 1 & sales_2015 == 0 , 1, 0)]
data[,f_defaulted := factor(defaulted)] # random forest can operate with factor but cannot with characters
data <- data[!(sales_2011 == 0 & sales_2012 == 0 & sales_2013 == 0
                         #& sales_2014 == 0 & sales_2015 == 0
                         )]

## Creating a list of companies that we are going to include
list_of_companies <- data[, unique(comp_id)]
```

Sales seemed to be an interesting predictor, so I have computed the change in sales from year to year.

```{r include=FALSE}
## Creating a table with unique company IDs and labor values from all years
data_labor_avg <- bisnode_all[, c("comp_id", "labor_avg", "year")]
data_labor_avg <- spread(data_labor_avg, key = year, value = labor_avg)
is.data.table(data_labor_avg)
names(data_labor_avg) <- c("comp_id", "labor_2011", "labor_2012", "labor_2013", "labor_2014", "labor_2015", "labor_2016")
str(data_labor_avg)

## Including only the companies that were dropped previously
data_labor_avg <- data_labor_avg[comp_id %in% list_of_companies]

## Computing the percentage changes in sales from year to year
data_labor_avg[, labor_change_11_12 := labor_2012/labor_2011]
data_labor_avg[, labor_change_12_13 := labor_2013/labor_2012]
data_labor_avg[, labor_change_13_14 := labor_2014/labor_2013]
data_labor_avg[, labor_change_14_15 := labor_2015/labor_2014]

data_labor_avg[,"labor_2016" := NULL]

## Merging it to the bigger table
data <- merge(data, data_labor_avg, all = TRUE)

#data_labor_avg <- data_labor_avg[complete.cases(data_wide[,2:4]),]
```

I am expecting company age to be an relevant predictor, I am assuming that the older a company, the more stable it is and the less likely it is to default.

```{r include=FALSE}
## Adding company age
data_founded_year <- bisnode_all[, c("comp_id", "founded_year", "year")]
data_founded_year <- spread(data_founded_year, key = year, value = founded_year)
names(data_founded_year) <- c("comp_id", "year_2011", "year_2012", "year_2013", "year_2014", "year_2015", "year_2016")

data_founded_year <- data_founded_year[comp_id %in% list_of_companies]

data_founded_year[ , founded_year :=rowMeans(.SD, na.rm = TRUE), 
                   .SDcols = c("year_2011", "year_2012", "year_2013", "year_2014", "year_2015", "year_2016")]

data <- merge(data, data_founded_year, all = TRUE)

#test <- data
#test <- cbind(test,data_founded_year[,"founded_year"])

data <- data[,age := 2015 - founded_year]

## creating 5 years age groups
data[,agegroup:=cut(age, seq(0,35,5), right = F,include.lowest = T )]

## creating 1 year long age groups
data[,agegi:=cut(age, seq(0,35,1), right = F,include.lowest = T )]
data[,agesq:=age^2]
```

I have cut the observations into 5 years long age groups, please find a table below showing the number of observations in the different groups.

```{r}
data[,.(min_age = min(age) , max_age = max(age), n=.N ), by=agegroup]
str(data$age)
```

Region would be interesting predictor if it were relevant, I am going to investigate it.

```{r include=FALSE}
## Adding region
#data_region <- bisnode_all[, c("comp_id", "region_m", "year")]
#data_region <- spread(data_region, key = year, value = region_m)
#names(data_founded_year) <- c("comp_id", "year_2011", "year_2012", "year_2013", "year_2014", "year_2015", "year_2016")

data_region <- bisnode_all[, unique(region_m), by = comp_id]
colnames(data_region) <- c("comp_id", "region")
data_region <- data_region[comp_id %in% list_of_companies]
data <- merge(data, data_region, all = TRUE)
data[,f_region := factor(region)]
```

```{r include=FALSE}
## Creating a table with unique company IDs and profit loss values from all years
data_profit_loss_year <- bisnode_all[, c("comp_id", "profit_loss_year", "year")]
data_profit_loss_year <- spread(data_profit_loss_year, key = year, value = profit_loss_year)
names(data_profit_loss_year) <- c("comp_id", "profit_loss_2011", "profit_loss_2012", "profit_loss_2013", "profit_loss_2014", "profit_loss_2015", "profit_loss_2016")

## Dropping the year 2016, because when the data was gathered, not all the the companies have submitted their financial records for 2016.
data_profit_loss_year[,"profit_loss_2016" := NULL]
data_profit_loss_year <- data_profit_loss_year[comp_id %in% list_of_companies]

##############################################################################

## Creating a table with unique company IDs and shared equity values from all years
data_share_eq <- bisnode_all[, c("comp_id", "share_eq", "year")]
data_share_eq <- spread(data_share_eq, key = year, value = share_eq)
names(data_share_eq) <- c("comp_id", "share_eq_2011", "share_eq_2012", "share_eq_2013", "share_eq_2014", "share_eq_2015", "share_eq_2016")

## Dropping the year 2016, because when the data was gathered, not all the the companies have submitted their financial records for 2016.
data_share_eq[,"share_eq_2016" := NULL]
data_share_eq <- data_share_eq[comp_id %in% list_of_companies]

##############################################################################

## Creating a table with unique company IDs and income before tax values from all years
data_inc_bef_tax <- bisnode_all[, c("comp_id", "inc_bef_tax", "year")]
data_inc_bef_tax <- spread(data_inc_bef_tax, key = year, value = inc_bef_tax)
names(data_inc_bef_tax) <- c("comp_id", "income_bef_tax_2011", "income_bef_tax_2012", "income_bef_tax_2013", "income_bef_tax_2014", "income_bef_tax_2015", "income_bef_tax_2016")

## Dropping the year 2016, because when the data was gathered, not all the the companies have submitted their financial records for 2016.
data_inc_bef_tax[,"income_bef_tax_2016" := NULL]
data_inc_bef_tax <- data_inc_bef_tax[comp_id %in% list_of_companies]

##############################################################################

## Creating a table with unique company IDs and current assets values from all years
data_curr_assets <- bisnode_all[, c("comp_id", "curr_assets", "year")]
data_curr_assets <- spread(data_curr_assets, key = year, value = curr_assets)
names(data_curr_assets) <- c("comp_id", "curr_assets_2011", "curr_assets_2012", "curr_assets_2013", "curr_assets_2014", "curr_assets_2015", "curr_assets_2016")

## Dropping the year 2016, because when the data was gathered, not all the the companies have submitted their financial records for 2016.
data_curr_assets[,"curr_assets_2016" := NULL]
data_curr_assets <- data_curr_assets[comp_id %in% list_of_companies]

##############################################################################

## Creating a table with unique company IDs and current assets values from all years
data_fixed_assets <- bisnode_all[, c("comp_id", "fixed_assets", "year")]
data_fixed_assets <- spread(data_fixed_assets, key = year, value = fixed_assets)
names(data_fixed_assets) <- c("comp_id", "fixed_assets_2011", "fixed_assets_2012", "fixed_assets_2013", "fixed_assets_2014", "fixed_assets_2015", "fixed_assets_2016")

## Dropping the year 2016, because when the data was gathered, not all the the companies have submitted their financial records for 2016.
data_fixed_assets[,"fixed_assets_2016" := NULL]
data_fixed_assets <- data_fixed_assets[comp_id %in% list_of_companies]

##############################################################################

## Creating a table with unique company IDs and current assets values from all years
data_curr_liab <- bisnode_all[, c("comp_id", "curr_liab", "year")]
data_curr_liab <- spread(data_curr_liab, key = year, value = curr_liab)
names(data_curr_liab) <- c("comp_id", "curr_liab_2011", "curr_liab_2012", "curr_liab_2013", "curr_liab_2014", "curr_liab_2015", "curr_liab_2016")

## Dropping the year 2016, because when the data was gathered, not all the the companies have submitted their financial records for 2016.
data_curr_liab[,"curr_liab_2016" := NULL]
data_curr_liab <- data_curr_liab[comp_id %in% list_of_companies]

data <- merge(data, data_profit_loss_year, all = TRUE)
data <- merge(data, data_share_eq, all = TRUE)
data <- merge(data, data_inc_bef_tax, all = TRUE)
data <- merge(data, data_curr_assets, all = TRUE)
data <- merge(data, data_fixed_assets, all = TRUE)
data <- merge(data, data_curr_liab, all = TRUE)
```

```{r include=FALSE}
## ROE = Net_Income / Shareholders Equity
data[, ROE_2011 := profit_loss_2011 / share_eq_2011]
data[, ROE_2012 := profit_loss_2012 / share_eq_2012]
data[, ROE_2013 := profit_loss_2013 / share_eq_2013]
data[, ROE_2014 := profit_loss_2014 / share_eq_2014]
data[, ROE_2015 := profit_loss_2015 / share_eq_2015]

## ROCE - returnal on capital employed
#bisnode[, ROCE := inc_bef_tax / (curr_assets + fixed_assets - curr_liab)] 

data[, ROCE_2011 := income_bef_tax_2011 / (curr_assets_2011 + fixed_assets_2011 - curr_liab_2011)]
data[, ROCE_2012 := income_bef_tax_2012 / (curr_assets_2012 + fixed_assets_2012 - curr_liab_2012)]
data[, ROCE_2013 := income_bef_tax_2013 / (curr_assets_2013 + fixed_assets_2013 - curr_liab_2013)]
data[, ROCE_2014 := income_bef_tax_2014 / (curr_assets_2014 + fixed_assets_2014 - curr_liab_2014)]
data[, ROCE_2015 := income_bef_tax_2015 / (curr_assets_2015 + fixed_assets_2015 - curr_liab_2015)]
```

```{r include=FALSE}
## Adding industry codes
data_ind <- bisnode_all[, unique(ind), by = comp_id]
colnames(data_ind) <- c("comp_id", "ind")
data_ind <- data_ind[comp_id %in% list_of_companies]

data <- merge(data, data_ind, all = TRUE)
data[,f_ind := factor(ind)]

## Adding industry codes
data_ind2 <- bisnode_all[, unique(ind2), by = comp_id]
colnames(data_ind2) <- c("comp_id", "ind2")
data_ind2 <- data_ind2[comp_id %in% list_of_companies]
data <- merge(data, data_ind2, all = TRUE)
data[,f_ind2 := factor(ind2)]
```

```{r include=FALSE}
data [, size_third := quantile ((curr_assets_2014 + fixed_assets_2014), 0.33, na.rm = TRUE), by = ind]
data [, size_twothird := quantile ((curr_assets_2014 + fixed_assets_2014), 0.66, na.rm = TRUE), by = ind]
data [, size_cat := cut (curr_assets_2014 + fixed_assets_2014, c(
                            0, size_third [1],
                            size_twothird [1], Inf),
                            labels = c("small", "medium", "big")),
                            by = ind]
#data[,f_size_cat := factor(size_cat)]
```

```{r include=FALSE}
## Dropping companies founded in 2014 or later, and companies founded before 1986
data <- data[founded_year<=2013]
data <- data[founded_year>=1986]

## Dropping companies with missing regions
data <- data[region != ""]

## Dropping companies with missing regions
test <- data[!(age == 35)]

## Dropping companies with missing industries
data <- data[ind != ""]
```

```{r}
#####################################################################
# CALIBRATION EXAMPLE
# AGE ONLY

logit <- glm(defaulted ~ age, family = "binomial", data=data)
logit
## storing the probability predictions in variable p
data$p <- predict(logit, data, type='response')

ggplot(data = data, aes(x=age , y=p)) +
  geom_line(size=1, colour="darkgreen", linetype=2 ) +
  geom_smooth(aes(x=age , y=defaulted), method="loess", colour="orange", se=F)+
  ylab("Probability of dying within six years") +
  theme_bw()
#ggsave("logit_lpoly_age.png")


# calibration for all specific values
data[,.(mean = mean(defaulted)), by=p>0.5]

#calibration for 10 groups of p, equal # obs
data[,pcat:=cut(p,10)]
cal10 <- data[,.(mean_y = mean(defaulted), mean_p = mean(p) ), by=pcat]

#calibration for 10 groups of p, equal width
data[,pcat:=cut(p, seq(0,1,0.02), right = F,include.lowest = T )]
cal10_2 <- data[,.(mean_y = mean(defaulted), mean_p = mean(p), min = min(p) , max = max(p), n=.N ), by=pcat]

ggplot(data = cal10, aes(x=mean_p, y=mean_y)) +
  geom_line(aes(x=mean_p,y=mean_p), size=1, colour="orange",  linetype=2 )+
  geom_line(size=2, colour="darkgreen")+
  xlab("Mean predicted probability") +
  ylab("") +
  theme_bw()
#ggsave("calibration.png")
```

```{r}
##############################################################################
# BRIER SCORES

logit2 <- glm(defaulted ~ 1, family = "binomial", data=data)
data$p2 <- predict(logit2, data, type='response')

BrierScore(logit)
BrierScore(logit2)
```

```{r}
#############################################################################
# ROC CURVE

roc(data$defaulted , data$p, plot=T)
```

```{r}
#################################Separate a test set for final evaluation

set.seed(2801)
# create test and train samples (80% of observations in train sample)
smp_size <- floor(0.8 * nrow(data))

# create ids: 
# 1) seq_len: generate regular sequences
# 2) sample: select random rows from a table
train_ids <- sample(seq_len(nrow(data)), size = smp_size)

# create a new variable for train/test sample
data$train <- 0
data$train[train_ids] <- 1
# Create train and test sample variables
d_train <- data[train==1,]
d_test <- data[train==0,]
```

```{r}
#############################################################################
Y = "defaulted"
# FOUR MODELS

m1 <- get(Y) ~ age 
m2 <- get(Y) ~ agegroup + region
#+ sales_change_12_13 + sales_change_13_14 + sales_change_14_15
m3 <- get(Y) ~ age + region + f_ind
  #+ labor_change_11_12 + labor_change_12_13 + labor_change_13_14 + labor_change_14_15
m4 <- get(Y) ~ agesq

###########################################################################
## IN-SAMPLE

in_sample_brier <- list()
in_sample_auc <- list()

for (i in 1:4){
  name <- paste("logit",2+i,sep="")
  logit <- glm(get(paste("m",i,sep='')), family = "binomial", data=d_train, na.action=na.pass)
  d_train[, (paste('p',2+i, sep=''))] <- predict(logit, d_train, type='response')
  #print(summary(logit))
  in_sample_brier[[paste0("m",i)]] <- BrierScore(logit) 
  in_sample_auc[[paste0("m",i)]] <- roc(d_train[,get(Y)] , d_train[,get(paste('p',2+i, sep=''))] , plot=F)$auc
  assign(name,logit)
}
```

```{r}
################################################################
## 5-FOLD CROSS-VALIDATION

set.seed(34167)

n_folds=5
# Create the folds
folds_i <- sample(rep(1:n_folds, length.out = nrow(d_train) ))

cv_results<-list()

for (i in 1:4){
  BRIER <- 0
  ROCAREA <- 0
  for (t in 1:n_folds){
    test_i <- which(folds_i == t)
    # Train sample: all except test_i
    data_train <- d_train[-test_i, ]
    # Test sample
    data_test <- d_train[test_i, ]
    logit <- glm(get(paste("m",i,sep='')), family = "binomial", data=data_train)
    p <- predict(logit, newdata=data_test , type='response')
    BRIER=BRIER + BrierScore(data_test[,get(Y)],p)
    ROCAREA=ROCAREA+ roc(data_test[,get(Y)] , p, plot=F)$auc
  }
  cv_results[[paste("model ",i,sep='')]] <- c("BRIER_SCORE"= BRIER/5 , "ROC_AREA"=ROCAREA/5)
}

cv_results
```

```{r}
####################################RANDOM FOREST

mrf <- f_defaulted ~ age + f_region + agegroup + f_ind# + size_cat

md <- randomForest(mrf, data = d_train, ntree = 200, mtry=3)
print(md)
varImpPlot(md, type = 2)


# look at two conf matrix
phat <- predict(md, data_test, type = "prob")[,"1"]
table(ifelse(phat>0.05,1,0), data_test$f_defaulted)
table(ifelse(phat>0.10,1,0), data_test$f_defaulted)
```

```{r}
################################################

# for comparison, train-test logits

logit_best <- glm(m2, family = "binomial", data=d_train)
p <- predict(logit_best, newdata=d_test , type='response')
BrierScore(d_test[,get(Y)],p)
plot.roc(d_test[,get(Y)] , p, print.auc = TRUE)

model.test.prob <- predict(md, d_test, type = "prob",norm.votes = TRUE)
plot.roc(predictor = model.test.prob[,2],  d_test$f_defaulted, print.auc = TRUE)
```





```{r eval=FALSE}
######################CLEAN DATA

data <- data[(age>=50) & (age<80)]
data <- data[(!is.na(smokes)) & (!is.na(ever_smoked)) & (!is.na(deceased)) &
               (!is.na(female)) & (!is.na(eduyears_mod)) & (!is.na(income10g)) ]  

## creating 5 yeats age groups
data[,agegroup:=cut(age, seq(50,80,5), right = F,include.lowest = T )]
## creating 1 year long age groups
data[,agegi:=cut(age, seq(50,80,1), right = F,include.lowest = T )]
data[,agesq:=age^2]
data[,.(min_age = min(age) , max_age = max(age), n=.N ), by=agegroup]

data[eduyears_mod==10.5,eduyears_mod:=10 ]
data[eduyears_mod==17.5,eduyears_mod:=17 ]
data <- data[eduyears_mod!=0]

## making edu_years and income10g factors
data[,f_eduyears_mod:=factor(eduyears_mod)]
data[,f_income10g:=factor(income10g)]
# for RF we will need as factor - this is what we are gonna predict
data[,f_deceased:=factor(deceased)]
class(data$f_deceased)

Y = "defaulted"
```

```{r eval=FALSE}
# number of unique company IDs
data[, comp_id := factor(comp_id)]
# number of unique company IDs
data[, year := factor(year)]
N_comp_id <- data[, length(unique(comp_id))]
N_year <- data[, length(unique(year))]
list_of_companies <- data[, unique(comp_id)]
list_of_years <- data[, unique(year)]

data_comp <- matrix(rep(NaN,N_comp_id*N_year),nrow=N_comp_id,ncol=N_year)
rownames(data_comp) <- list_of_companies
colnames(data_comp) <- c("sales_2011", "sales_2012", "sales_2013", "sales_2014", "sales_2015", "sales_2016")

i <- 1
j <- 1

for ( comp in list_of_companies ){
  for ( year_in_column in c("2011", "2012", "2013", "2014", "2015", "2016") ){
    if (length(data[comp_id == comp & year == year_in_column, sales]) == 0){
      j <- j + 1
    } else {
    data_comp[i,j] <- data[comp_id == comp & year == year_in_column, sales]
    j <- j + 1
    }
  }
  i <- i + 1
  j <- 1
  }

## It is a bad idea doing this way as it takes too long to aggregate the data
#fwrite(data_comp,"data_comp.csv")

#data_comp[i,j] <- data[comp_id == 1004012, sales]
#c("2011", "2012", "2013", "2014", "2015", "2016")


#data_comp[1,1] <- data[comp_id == comp & year == 2010, sales]
#length(data[comp_id == comp & year == 2010, sales])
#length(data[comp_id == comp & year == year, sales])
```

```{r eval=FALSE}
#data_wide_cleaned <- data_wide[(!is.na("sales_2011")) & (!is.na("sales_2012")) & (!is.na("sales_2013")) & (!is.na("sales_2014")) & (!is.na("sales_2015"))]
#data_wide_cleaned <- data_wide[(!is.na(2011)) & (!is.na(2012)) & (!is.na(2013))& (!is.na(2014))& (!is.na(2015))& (!is.na(2016))]
#data_wide_cleaned <- data_wide[(!is.na(2)) & (!is.na(3)) & (!is.na(4))& (!is.na(5))& (!is.na(6))& (!is.na(7))]
#data_wide_cleaned <- data_wide[(!is.na("2011")) && (!is.na("2012")) && (!is.na("2013")) && (!is.na("2014")) && (!is.na("2015")) && (!is.na("2016"))]
#data_wide_cleaned <- data_wide[(!is.na("2011")) & (!is.na("2012")) & (!is.na("2013")) & (!is.na("2014")) & (!is.na("2015")) & (!is.na("2016"))]
#data_wide_cleaned <- data_wide[(is.na("2011")) & (is.na("2012")) & (is.na("2013")) & (is.na("2014")) & (is.na("2015")) & (is.na("2016"))]
#data_wide_cleaned <- data_wide[complete.cases(data_wide[,2:5]),]

#data_wide_cleaned_2 <- data_wide_cleaned["sales_2011" != 0 & "sales_2012" != 0 & "sales_2013" != 0 & "sales_2014" != 0 & "sales_2015" != 0]

#data_wide[, defaulted := factor(levels = c("Yes", "No"))]
data_wide[, defaulted := ifelse(is.na(7), 1, 0)]
data_wide_cleaned[1,7]
is.na(data_wide_cleaned[3,7])
data_wide[1:3, default_binary := factor(ifelse(is.na(7), 1, 0))]

is.na(data_wide[1,2])
is.na(data_wide[1,7])

data_wide[, sales_2011 := as.integer(sales_2011)]
data_wide[, sales_2016 := as.integer(sales_2016)]
str(data_wide)


data_wide[, sales_2011_is_NA := factor(ifelse(is.na(data_wide[,2]), 1, 0))]
data_wide[, sales_2016_is_NA := factor(ifelse(is.na(data_wide[,7]), 1, 0))]
```