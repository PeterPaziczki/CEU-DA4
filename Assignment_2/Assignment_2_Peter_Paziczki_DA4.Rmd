---
title: "Homework assignment 2"
author: "Peter Paziczki"
date: "2018 February 18"
output:
  pdf_document: default
  html_document: default
subtitle: 'Data Analysis 4: Prediction Analytics with Introduction to Machine Learning
  2017/2018 Winter'
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, echo = FALSE)
options(scipen=999) #disable scientific notation
```

```{r echo=FALSE}
# loading necessary 
library(data.table)
library(ggplot2)
library(tidyr)
library(DescTools) # for BrierScore function
library(pROC) # for roc function
library(dplyr)
library(randomForest)
#library(lattice)
#library(caret)
#library(glmnet)
```

```{r}
getwd()
# Loading the data
bisnode_all <- fread("bisnode_all.csv")
```

```{r}
## Creating a table with unique company IDs and sales values from all years
data_sales <- bisnode_all[, c("comp_id", "sales", "year")]
data_sales <- spread(data_sales, key = year, value = sales)
#is.data.table(data_sales)
names(data_sales) <- c("comp_id", "sales_2011", "sales_2012", "sales_2013", "sales_2014", "sales_2015", "sales_2016")
str(data_sales)

data_sales[,"sales_2016" := NULL]
data <- data_sales[complete.cases(data_sales[,c("sales_2011", "sales_2012", "sales_2013")]),]
```

```{r}
## computing the percentage changes in sales from year to year
data[, sales_change_11_12 := sales_2012/sales_2011]
data[, sales_change_12_13 := sales_2013/sales_2012]
data[, sales_change_13_14 := sales_2014/sales_2013]
data[, sales_change_14_15 := sales_2015/sales_2014]
```

```{r}
## Creating binary variables

#data[, sales_2011_is_NA := factor(ifelse(is.na(data[,sales_2011]), 1, 0))]
#data[, sales_2012_is_NA := factor(ifelse(is.na(data[,sales_2012]), 1, 0))]
#data[, sales_2013_is_NA := factor(ifelse(is.na(data[,sales_2013]), 1, 0))]
data[, sales_2014_is_NA := factor(ifelse(is.na(data[,sales_2014]), 1, 0))]
data[, sales_2015_is_NA := factor(ifelse(is.na(data[,sales_2015]), 1, 0))]
#data[, sales_2016_is_NA := factor(ifelse(is.na(data[,sales_2016]), 1, 0))]
```

```{r}
#data[,defaulted := factor(ifelse(sales_2014_is_NA == 1 & sales_2015_is_NA == 1, 1, 0))]
data[,defaulted := ifelse(sales_2014_is_NA == 1 & sales_2015_is_NA == 1 | 
                                        sales_2014 == 0 & sales_2015 == 0 | 
                                        sales_2014 == 0 & sales_2015_is_NA == 1 |
                                        sales_2014_is_NA == 1 & sales_2015 == 0 , 1, 0)]
data[,f_defaulted := factor(defaulted)]
data <- data[!(sales_2011 == 0 & sales_2012 == 0 & sales_2013 == 0
                         #& sales_2014 == 0 & sales_2015 == 0
                         )]

list_of_companies <- data[, unique(comp_id)]
```


```{r}
## Creating a table with unique company IDs and sales values from all years
data_labor_avg <- bisnode_all[, c("comp_id", "labor_avg", "year")]
data_labor_avg <- spread(data_labor_avg, key = year, value = labor_avg)
is.data.table(data_labor_avg)
names(data_labor_avg) <- c("comp_id", "labor_2011", "labor_2012", "labor_2013", "labor_2014", "labor_2015", "labor_2016")
str(data_labor_avg)

data_labor_avg <- data_labor_avg[comp_id %in% list_of_companies]

## computing the percentage changes in sales from year to year
data_labor_avg[, labor_change_11_12 := labor_2012/labor_2011]
data_labor_avg[, labor_change_12_13 := labor_2013/labor_2012]
data_labor_avg[, labor_change_13_14 := labor_2014/labor_2013]
data_labor_avg[, labor_change_14_15 := labor_2015/labor_2014]

#N <- ncol(data_labor_avg)

data <- merge(data, data_labor_avg, all = TRUE)

#data_labor_avg[,"labor_2016" := NULL]
#data_labor_avg <- data_labor_avg[complete.cases(data_wide[,2:4]),]
```

```{r}
## adding age
data_founded_year <- bisnode_all[, c("comp_id", "founded_year", "year")]
data_founded_year <- spread(data_founded_year, key = year, value = founded_year)
names(data_founded_year) <- c("comp_id", "year_2011", "year_2012", "year_2013", "year_2014", "year_2015", "year_2016")

data_founded_year <- data_founded_year[comp_id %in% list_of_companies]

data_founded_year[ , founded_year :=rowMeans(.SD, na.rm = TRUE), 
                   .SDcols = c("year_2011", "year_2012", "year_2013", "year_2014", "year_2015", "year_2016")]

data <- merge(data, data_founded_year, all = TRUE)

#test <- data
#test <- cbind(test,data_founded_year[,"founded_year"])

data <- data[,age := 2015 - founded_year]
```

```{r}
## adding region
#data_region <- bisnode_all[, c("comp_id", "region_m", "year")]
#data_region <- spread(data_region, key = year, value = region_m)
#names(data_founded_year) <- c("comp_id", "year_2011", "year_2012", "year_2013", "year_2014", "year_2015", "year_2016")

data_region <- bisnode_all[, unique(region_m), by = comp_id]
colnames(data_region) <- c("comp_id", "region")
data_region <- data_region[comp_id %in% list_of_companies]
data <- merge(data, data_region, all = TRUE)
data[,f_region := factor(region)]
## Dropping companies with missing 
#data[comp_id == "425522272",region]
data <- data[region != ""]
#data <- data[region == ""]
```

```{r}
data <- data[founded_year<=2013]
```

```{r eval=FALSE}
######################CLEAN DATA

data <- data[(age>=50) & (age<80)]
data <- data[(!is.na(smokes)) & (!is.na(ever_smoked)) & (!is.na(deceased)) &
               (!is.na(female)) & (!is.na(eduyears_mod)) & (!is.na(income10g)) ]  

## creating 5 yeats age groups
data[,agegroup:=cut(age, seq(50,80,5), right = F,include.lowest = T )]
## creating 1 year long age groups
data[,agegi:=cut(age, seq(50,80,1), right = F,include.lowest = T )]
data[,agesq:=age^2]
data[,.(min_age = min(age) , max_age = max(age), n=.N ), by=agegroup]

data[eduyears_mod==10.5,eduyears_mod:=10 ]
data[eduyears_mod==17.5,eduyears_mod:=17 ]
data <- data[eduyears_mod!=0]

## making edu_years and income10g factors
data[,f_eduyears_mod:=factor(eduyears_mod)]
data[,f_income10g:=factor(income10g)]
# for RF we will need as factor - this is what we are gonna predict
data[,f_deceased:=factor(deceased)]
class(data$f_deceased)

Y = "defaulted"
```

```{r}
#####################################################################
# CALIBRATION EXAMPLE
# AGE ONLY

logit <- glm(defaulted ~ age, family = "binomial", data=data)
logit
## storing the probability predictions in variable p
data$p <- predict(logit, data, type='response')

ggplot(data = data, aes(x=age , y=p)) +
  geom_line(size=1, colour="darkgreen", linetype=2 ) +
  geom_smooth(aes(x=age , y=defaulted), method="loess", colour="orange", se=F)+
  ylab("Probability of dying within six years") +
  theme_bw()
#ggsave("logit_lpoly_age.png")


# calibration for all specific values
data[,.(mean = mean(defaulted)), by=p>0.5]

#calibration for 10 groups of p, equal # obs
data[,pcat:=cut(p,10)]
cal10 <- data[,.(mean_y = mean(defaulted), mean_p = mean(p) ), by=pcat]

#calibration for 10 groups of p, equal width
data[,pcat:=cut(p, seq(0,1,0.02), right = F,include.lowest = T )]
cal10_2 <- data[,.(mean_y = mean(defaulted), mean_p = mean(p), min = min(p) , max = max(p), n=.N ), by=pcat]

ggplot(data = cal10, aes(x=mean_p, y=mean_y)) +
  geom_line(aes(x=mean_p,y=mean_p), size=1, colour="orange",  linetype=2 )+
  geom_line(size=2, colour="darkgreen")+
  xlab("Mean predicted probability") +
  ylab("") +
  theme_bw()
#ggsave("calibration.png")
```

```{r}
##############################################################################
# BRIER SCORES

logit2 <- glm(defaulted ~ 1, family = "binomial", data=data)
data$p2 <- predict(logit2, data, type='response')

BrierScore(logit)
BrierScore(logit2)
```

```{r}
#############################################################################
# ROC CURVE

roc(data$defaulted , data$p, plot=T)
```

```{r}
#################################Separate a test set for final evaluation

set.seed(2801)
# create test and train samples (80% of observations in train sample)
smp_size <- floor(0.8 * nrow(data))

# create ids: 
# 1) seq_len: generate regular sequences
# 2) sample: select random rows from a table
train_ids <- sample(seq_len(nrow(data)), size = smp_size)

# create a new variable for train/test sample
data$train <- 0
data$train[train_ids] <- 1
# Create train and test sample variables
d_train <- data[train==1,]
d_test <- data[train==0,]
```

```{r}
#############################################################################
Y = "defaulted"
# FOUR MODELS

m1 <- get(Y) ~ age 
m2 <- get(Y) ~ region
  #+ region + sales_change_11_12 + sales_change_12_13 + sales_change_13_14 + sales_change_14_15
m3 <- get(Y) ~ age + region
  #+ labor_change_11_12 + labor_change_12_13 + labor_change_13_14 + labor_change_14_15
m4 <- get(Y) ~ age

###########################################################################
## IN-SAMPLE

in_sample_brier <- list()
in_sample_auc <- list()

str(data)

for (i in 1:4){
  name <- paste("logit",2+i,sep="")
  logit <- glm(get(paste("m",i,sep='')), family = "binomial", data=d_train, na.action=na.pass)
  d_train[, (paste('p',2+i, sep=''))] <- predict(logit, d_train, type='response')
  #print(summary(logit))
  in_sample_brier[[paste0("m",i)]] <- BrierScore(logit) 
  in_sample_auc[[paste0("m",i)]] <- roc(d_train[,get(Y)] , d_train[,get(paste('p',2+i, sep=''))] , plot=F)$auc
  assign(name,logit)
}
```

```{r}
################################################################
## 5-FOLD CROSS-VALIDATION

set.seed(34167)

n_folds=5
# Create the folds
folds_i <- sample(rep(1:n_folds, length.out = nrow(d_train) ))

cv_results<-list()

for (i in 1:4){
  BRIER <- 0
  ROCAREA <- 0
  for (t in 1:n_folds){
    test_i <- which(folds_i == t)
    # Train sample: all except test_i
    data_train <- d_train[-test_i, ]
    # Test sample
    data_test <- d_train[test_i, ]
    logit <- glm(get(paste("m",i,sep='')), family = "binomial", data=data_train)
    p <- predict(logit, newdata=data_test , type='response')
    BRIER=BRIER + BrierScore(data_test[,get(Y)],p)
    ROCAREA=ROCAREA+ roc(data_test[,get(Y)] , p, plot=F)$auc
  }
  cv_results[[paste("model ",i,sep='')]] <- c("BRIER_SCORE"= BRIER/5 , "ROC_AREA"=ROCAREA/5)
}

cv_results
```

```{r}
####################################RANDOM FOREST

mrf <- f_defaulted ~ age + f_region

md <- randomForest(mrf, data = d_train, ntree = 200, mtry=3)
print(md)
varImpPlot(md, type = 2)


# look at two conf matrix
phat <- predict(md, data_test, type = "prob")[,"1"]
table(ifelse(phat>0.05,1,0), data_test$f_defaulted)
table(ifelse(phat>0.10,1,0), data_test$f_defaulted)
```

```{r}
################################################

# for comparison, train-test logits

logit_best <- glm(m2, family = "binomial", data=d_train)
p <- predict(logit_best, newdata=d_test , type='response')
BrierScore(d_test[,get(Y)],p)
plot.roc(d_test[,get(Y)] , p, print.auc = TRUE)

model.test.prob <- predict(md, d_test, type = "prob",norm.votes = TRUE)
plot.roc(predictor = model.test.prob[,2],  d_test$f_defaulted, print.auc = TRUE)
```


```{r eval=FALSE}
# number of unique company IDs
data[, comp_id := factor(comp_id)]
# number of unique company IDs
data[, year := factor(year)]
N_comp_id <- data[, length(unique(comp_id))]
N_year <- data[, length(unique(year))]
list_of_companies <- data[, unique(comp_id)]
list_of_years <- data[, unique(year)]

data_comp <- matrix(rep(NaN,N_comp_id*N_year),nrow=N_comp_id,ncol=N_year)
rownames(data_comp) <- list_of_companies
colnames(data_comp) <- c("sales_2011", "sales_2012", "sales_2013", "sales_2014", "sales_2015", "sales_2016")

i <- 1
j <- 1

for ( comp in list_of_companies ){
  for ( year_in_column in c("2011", "2012", "2013", "2014", "2015", "2016") ){
    if (length(data[comp_id == comp & year == year_in_column, sales]) == 0){
      j <- j + 1
    } else {
    data_comp[i,j] <- data[comp_id == comp & year == year_in_column, sales]
    j <- j + 1
    }
  }
  i <- i + 1
  j <- 1
  }

## It is a bad idea doing this way as it takes too long to aggregate the data
#fwrite(data_comp,"data_comp.csv")

#data_comp[i,j] <- data[comp_id == 1004012, sales]
#c("2011", "2012", "2013", "2014", "2015", "2016")


#data_comp[1,1] <- data[comp_id == comp & year == 2010, sales]
#length(data[comp_id == comp & year == 2010, sales])
#length(data[comp_id == comp & year == year, sales])
```

```{r eval=FALSE}
#data_wide_cleaned <- data_wide[(!is.na("sales_2011")) & (!is.na("sales_2012")) & (!is.na("sales_2013")) & (!is.na("sales_2014")) & (!is.na("sales_2015"))]
#data_wide_cleaned <- data_wide[(!is.na(2011)) & (!is.na(2012)) & (!is.na(2013))& (!is.na(2014))& (!is.na(2015))& (!is.na(2016))]
#data_wide_cleaned <- data_wide[(!is.na(2)) & (!is.na(3)) & (!is.na(4))& (!is.na(5))& (!is.na(6))& (!is.na(7))]
#data_wide_cleaned <- data_wide[(!is.na("2011")) && (!is.na("2012")) && (!is.na("2013")) && (!is.na("2014")) && (!is.na("2015")) && (!is.na("2016"))]
#data_wide_cleaned <- data_wide[(!is.na("2011")) & (!is.na("2012")) & (!is.na("2013")) & (!is.na("2014")) & (!is.na("2015")) & (!is.na("2016"))]
#data_wide_cleaned <- data_wide[(is.na("2011")) & (is.na("2012")) & (is.na("2013")) & (is.na("2014")) & (is.na("2015")) & (is.na("2016"))]
#data_wide_cleaned <- data_wide[complete.cases(data_wide[,2:5]),]

#data_wide_cleaned_2 <- data_wide_cleaned["sales_2011" != 0 & "sales_2012" != 0 & "sales_2013" != 0 & "sales_2014" != 0 & "sales_2015" != 0]

#data_wide[, defaulted := factor(levels = c("Yes", "No"))]
data_wide[, defaulted := ifelse(is.na(7), 1, 0)]
data_wide_cleaned[1,7]
is.na(data_wide_cleaned[3,7])
data_wide[1:3, default_binary := factor(ifelse(is.na(7), 1, 0))]

is.na(data_wide[1,2])
is.na(data_wide[1,7])

data_wide[, sales_2011 := as.integer(sales_2011)]
data_wide[, sales_2016 := as.integer(sales_2016)]
str(data_wide)


data_wide[, sales_2011_is_NA := factor(ifelse(is.na(data_wide[,2]), 1, 0))]
data_wide[, sales_2016_is_NA := factor(ifelse(is.na(data_wide[,7]), 1, 0))]
```